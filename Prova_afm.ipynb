{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fb81ca-f3a5-41d2-be53-bb5dcceea7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40495ed3-f46b-456c-95af-3da085a8856c",
   "metadata": {},
   "source": [
    "La prossima funzione ci permette di generare i gruppi dei nostri file hdf5 leggendo la struttura dei json i quali saranno del tipo:\n",
    "{\n",
    "    \"a\": str,\n",
    "    \"b\": {\n",
    "        \"value\": number,\n",
    "        \"unit\": str\n",
    "    }\n",
    "    \"c\": {\n",
    "        \"m_def\": \"NX_class\",\n",
    "        \"name\":str,\n",
    "        ...\n",
    "    }\n",
    "}\n",
    "\n",
    "La funzione in pratica verrà usata quando raggiungendo il livello di \"c\" userà \"c\" per nominare il gruppo (infatti le chiavi dei json sono costruite in base a ciò che si aspetta il file nexus) e userà l'oggetto in \"m_def\" per prendere il TYPE. La posizione va assegnata ma c'è un trick utile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd84de23-184b-4069-9a15-1550733d8ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_group_to_fill(TYPE, where, name):\n",
    "    group=where.create_group(name)\n",
    "    group.attrs[\"NX_class\"]=TYPE\n",
    "    return group"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1cfa82a1-de5d-4b6b-851d-de95748ed708",
   "metadata": {},
   "source": [
    "Adesso che sappiamo generare i gruppi possiamo in teoria preoccuparci di scrivere le quantità in questi gruppi. Potremmo avere quantità stringa (le più semplici) che vengono lette e scritte come dataset del gruppo. I valori numerici senza unità di misura possono essere trattati come le stringhe. Abbiamo poi la possibilità di avere grandezze scalari con unità di misura, oppure grandezze vettoriali (simili alle scalari ma con un versore direzione associato). Infine potremmo trovare altri gruppi come elementi di un altro gruppo per cui quando arriviamo a quel punto usiamo \"m_def\" come spiegato prima per generare un altro gruppo dentro il gruppo in cui stiamo lavorando (l'attuale where) e riprocediamo a scriverne le quantità modificando i dati che scrviamo (quelli del nuovo gruppo salvati da dati[row]) e scrivendoli nel gruppo restituito dalla funzione precedente. Iteriamo fino al completamento del json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3911ccbb-ff9a-47c0-91c8-f62bba088caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(dati, where):\n",
    "    for row in dati:\n",
    "        if (isinstance(dati[row], str) and row != \"m_def\") or isinstance(dati[row], (int, float, bool)):\n",
    "            where.create_dataset(row, data=dati[row])\n",
    "        elif isinstance(dati[row], dict):\n",
    "            if dati[row].keys() == {\"value\", \"unit\", \"direction\"}:\n",
    "                where.create_dataset(row, data=dati[row][\"value\"])\n",
    "                where[row].attrs[\"units\"]=dati[row][\"unit\"]\n",
    "                where[row].attrs[\"direction\"] = dati[row][\"direction\"]\n",
    "            elif dati[row].keys() <= {\"value\", \"unit\"}:\n",
    "                where.create_dataset(row, data=dati[row][\"value\"])\n",
    "                where[row].attrs[\"units\"]=dati[row][\"unit\"]\n",
    "            elif \"m_def\" in dati[row].keys():\n",
    "                newwhere=create_group_to_fill(dati[row][\"m_def\"], where, row)\n",
    "                write_data(dati[row], newwhere)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83a84d5b-40a2-45d0-94d4-a7286fe22f7c",
   "metadata": {},
   "source": [
    "Piccola funzione per leggere e caricare il contenuto di un json come dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d788412-b242-4ff9-99ed-2985544c8bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_from_json(json_input, where):\n",
    "    with open(json_input, \"r\", encoding=\"utf-8\") as file:\n",
    "        dati = json.load(file)\n",
    "        write_data(dati, where)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42663210-c2c9-4520-b6d8-a4ea8c11ce81",
   "metadata": {},
   "source": [
    "Funzione per aprire json multipli avendo comunque cura di aprire per primo il file contenente le informazioni dell'entry (il top level dei nostri nexus). E poi dovendo dare sempre un sample, uno strumento e uno user generiamo a monte i gruppi per quelle sottoentries così non serve m_def a inizio di ogni file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f11c47d9-dbe9-42eb-a856-75302b13e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aprire_jsons(directory, entry):\n",
    "    for file in os.listdir(directory):\n",
    "        if Path(file).suffix == \".json\" and \"entry\" in file:\n",
    "            write_from_json(os.path.join(directory, file), entry)\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        if Path(file).suffix == \".json\" and \"sample\" in file:\n",
    "            sample=create_group_to_fill(\"NXsample\", entry, \"sample\")\n",
    "            write_from_json(os.path.join(directory, file), sample)\n",
    "        if Path(file).suffix == \".json\" and \"user\" in file:\n",
    "            user=create_group_to_fill(\"NXuser\", entry, \"user\")\n",
    "            write_from_json(os.path.join(directory, file), user)\n",
    "        if Path(file).suffix == \".json\" and \"instrument\" in file:\n",
    "            instr=create_group_to_fill(\"NXinstrument\", entry, \"instrument\")\n",
    "            write_from_json(os.path.join(directory, file), instr)\n",
    "            "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8dba2fa-8c11-4d53-a0b4-476132efb6bd",
   "metadata": {},
   "source": [
    "Finalmente scriviamo il fil per l'afm leggendo i vari jsons nella directory attuale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63c918b0-35b8-4c79-8114-366351e13332",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"afm_file_auto1.nxs\", \"w\") as f:\n",
    "    entry = f.create_group(\"entry\")\n",
    "    entry.attrs[\"NX_class\"] = \"NXentry\"\n",
    "    entry.create_dataset(\"definition\", data=\"NXafm\")\n",
    "    entry[\"definition\"].attrs[\"version\"] = \"v2024.02\"\n",
    "    entry[\"definition\"].attrs[\"URL\"] = \"https://github.com/FAIRmat-NFDI/nexus_definitions/blob/fairmat/contributed_definitions/NXafm.nxdl.xml\"\n",
    "    aprire_jsons(\"./jsons_for_afm/\" , entry)\n",
    "    #### Completiamo generando i link necessari\n",
    "    scan = entry[\"instrument\"].create_group (\"scan_environment\")\n",
    "    scan.attrs[\"NX_class\"] = \"NXenvironment\"\n",
    "    scan[\"height_piezo_sensor\"] = entry[\"instrument\"][\"height_piezo_sensor\"]\n",
    "    scan[\"XY_piezo_sensor\"] = entry[\"instrument\"][\"XY_piezo_sensor\"]\n",
    "    scan[\"tip_temp_sensor\"] = entry[\"instrument\"][\"tip_temp_sensor\"]\n",
    "    scan.create_dataset(\"tip_temp\", data=25)\n",
    "    scan[\"tip_temp\"].attrs[\"units\"] = \"celsius\"\n",
    "    #### Reproducibility indicators\n",
    "    reprind = entry.create_group(\"reproducibility_indicators\")\n",
    "    reprind.attrs[\"NX_class\"] = \"NXcollection\"\n",
    "    reprind[\"cantilever_oscillator\"] = entry[\"instrument\"][\"cantilever\"][\"cantilever_oscillator\"]\n",
    "    reprind[\"cantilever_tip_temp\"] = entry[\"instrument\"][\"scan_environment\"][\"tip_temp\"]\n",
    "    #### Resolution indicators\n",
    "    resind = entry.create_group(\"resolution_indicators\")\n",
    "    resind.attrs[\"NX_class\"] = \"NXcollection\"\n",
    "    resind[\"oscillator_excitation\"] = entry[\"instrument\"][\"cantilever\"][\"cantilever_oscillator\"][\"oscillator_excitation\"]\n",
    "    resind[\"cantilever_tip_temp\"] = entry[\"instrument\"][\"scan_environment\"][\"tip_temp\"]\n",
    "    resind[\"amplitude_excitation\"] = entry[\"instrument\"][\"cantilever\"][\"cantilever_oscillator\"][\"phase_lock_loop\"][\"amplitude_excitation\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aea53e17-85ff-4fb5-9e33-d20830626a24",
   "metadata": {},
   "source": [
    "Proviamo a fare una funzione anche per scrivere un file per il SEM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70f44e3c-2d71-491f-b0c9-32f503a435da",
   "metadata": {},
   "source": [
    "Nel SEM è importante caricare anche i dati provenienti dalle immagini per cui dobbiamo caricare i dati presenti nella cartella tiffs_for_sem. Creiamo la funzione per estrarre i metadati dall'immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f2640fc-9452-4879-a29b-c79da5bd6d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata salvati in metadata_tiff.json con 15 tag.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from PIL import Image, TiffTags\n",
    "from fractions import Fraction\n",
    "\n",
    "def convert_to_serializable(obj):\n",
    "    \"\"\"Converte tipi non serializzabili in formati compatibili JSON.\"\"\"\n",
    "    if isinstance(obj, bytes):\n",
    "        try:\n",
    "            return obj.decode(\"utf-8\", errors=\"replace\")\n",
    "        except Exception:\n",
    "            return list(obj)  # come lista di int\n",
    "    if isinstance(obj, (tuple, list)):\n",
    "        return [convert_to_serializable(x) for x in obj]\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): convert_to_serializable(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, Fraction):  # caso raro\n",
    "        return float(obj)\n",
    "    if hasattr(obj, \"numerator\") and hasattr(obj, \"denominator\"):\n",
    "        # caso IFDRational o simile\n",
    "        try:\n",
    "            return float(obj)\n",
    "        except Exception:\n",
    "            return str(obj)\n",
    "    if isinstance(obj, (int, float, str, bool)) or obj is None:\n",
    "        return obj\n",
    "    return str(obj)  # fallback: stringa\n",
    "\n",
    "def estrai_metadata_tiff(percorso_file):\n",
    "    \"\"\"Estrae tutti i metadata da un file TIFF, inclusi i tag personalizzati.\"\"\"\n",
    "    metadata = {}\n",
    "    with Image.open(percorso_file) as img:\n",
    "        metadata[\"format\"] = img.format\n",
    "        metadata[\"mode\"] = img.mode\n",
    "        metadata[\"size\"] = img.size\n",
    "\n",
    "        if hasattr(img, \"tag_v2\"):\n",
    "            tags = {}\n",
    "            for k, v in img.tag_v2.items():\n",
    "                tag_name = TiffTags.TAGS_V2.get(k, k)\n",
    "                try:\n",
    "                    hash(tag_name)\n",
    "                except TypeError:\n",
    "                    tag_name = str(tag_name)\n",
    "                tags[str(tag_name)] = convert_to_serializable(v)\n",
    "            metadata[\"tiff_tags\"] = tags\n",
    "\n",
    "    return metadata\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"./tiffs_for_sem/.tif\"\n",
    "    info = estrai_metadata_tiff(file_path)\n",
    "\n",
    "    # Salva in JSON senza errori\n",
    "    with open(\"metadata_tiff.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(info, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Metadata salvati in metadata_tiff.json con {len(info.get('tiff_tags', {}))} tag.\")\n",
    "\n",
    "    file_path = \"./tiffs_for_sem/U1502_metal_cross_5um_015.tif\"\n",
    "    info = estrai_metadata_tiff(file_path)\n",
    "    with open(\"metadata_tiff.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(info, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Metadata salvati in metadata_tiff.json con {len(info.get('tiff_tags', {}))} tag.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41ed7b8a-6da9-4d62-b3fb-9a6d69ddfe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"sem_file_auto.nxs\", \"w\") as f:\n",
    "    entry = f.create_group(\"entry\")\n",
    "    entry.attrs[\"NX_class\"] = \"NXentry\"\n",
    "    entry.create_dataset(\"definition\", data=\"NXem\")\n",
    "    entry[\"definition\"].attrs[\"version\"] = \"v2024.02\"\n",
    "    entry[\"definition\"].attrs[\"URL\"] = \"https://github.com/FAIRmat-NFDI/nexus_definitions/blob/a85e10cd0289f4e44b0fec011ff54703e6705383/contributed_definitions/NXem.nxdl.xml\"\n",
    "    entry.create_dataset(\"experiment_identifier\", data=\"experiment_id\")\n",
    "    aprire_jsons(\"./jsons_for_sem/\", entry)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "350daa26-b27a-4570-b2d4-4ac19cf26efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:NXroot\n",
      "  entry:NXentry\n",
      "    definition = 'NXem'\n",
      "      @URL = 'https://github.com/FAIRmat-NFDI/nexus_definiti...'\n",
      "      @version = 'v2024.02'\n",
      "    experiment_identifier = 'experiment_id'\n",
      "    sample:NXsample\n",
      "      is_simulation = True\n",
      "      name = 'Sample SEM'\n",
      "      physical_form = 'bulk'\n",
      "    user:NXuser\n",
      "      ORCID = '0009-0004-3810-1808'\n",
      "      address = 'Povo(TN)'\n",
      "      affiliation = 'FBK'\n",
      "      email = 'mbontorno@fbk.eu'\n",
      "      facility_user_id = 'MB'\n",
      "      name = 'Matteo Bontorno'\n",
      "      role = 'Collaborator'\n"
     ]
    }
   ],
   "source": [
    "from nexusformat.nexus import *\n",
    "\n",
    "test = nxload(\"sem_file_auto.nxs\")\n",
    "print(test.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf37276-a7bc-475f-ae2b-af9cfcc9344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterizationEquipmentEntryPoint(SchemaPackageEntryPoint):\n",
    "    def load(self):\n",
    "        from fabrication_facilities.schema_packages.equipments.character_equipment import (\n",
    "            m_package,\n",
    "        )\n",
    "\n",
    "        return m_package\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
