{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2c820697-85f7-43aa-8482-bb40228f5e29",
   "metadata": {},
   "source": [
    "Proviamo a fare una funzione anche per scrivere un file per il SEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147417f7-4a3c-4d58-bd76-8c9276477e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "import tifffile as tf\n",
    "import numpy as np\n",
    "from common import aprire_jsons, write_data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce41b066-073c-44a7-9683-fa3e84359053",
   "metadata": {},
   "source": [
    "Nel SEM è importante caricare anche i dati provenienti dalle immagini per cui dobbiamo caricare i dati presenti nella cartella tiffs_for_sem.\n",
    "Creiamo la funzione per estrarre i dati dall'immagine. Ho previsto il caso in cui ci possano essere più pagine per cui attualmente la funzione restituisce il nome del file da cui estrae i dati e i dati in una lista per ciascuna pagina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8c28c73f-9c53-49eb-b4ed-ed0a51f5619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_tif(tif_image):\n",
    "    name = tif_image.split(\"/\")[-1]\n",
    "    name = name.split(\".\")[0]\n",
    "    with tf.TiffFile(tif_image) as tiffile:\n",
    "        arrays=[]\n",
    "        for i, page in enumerate(tiffile.pages):\n",
    "            array = page.asarray()\n",
    "            # Convertiamo in uint16 preservando il range\n",
    "            if array.dtype != np.uint16:\n",
    "                array = (array / array.max() * 65535).astype(np.uint16)\n",
    "            arrays.append(array)\n",
    "    return name, arrays"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5935759d-6880-46fc-a657-0fa126fbd241",
   "metadata": {},
   "source": [
    "E vediamo come funziona con qualche comando nella prossima cella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160f6b73-a273-4364-9f41-cf73c626b925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run2_area_01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[37332, 36211, 35647, ..., 34984, 34567, 45084],\n",
       "        [46202, 40030, 44039, ..., 32821, 35233, 38766],\n",
       "        [35845, 35799, 37199, ..., 45670, 22978, 34718],\n",
       "        ...,\n",
       "        [25443, 13621, 13621, ..., 13621, 13621, 25443],\n",
       "        [25443, 13621, 13621, ..., 13621, 13621, 25443],\n",
       "        [25443, 25443, 25443, ..., 25443, 25443, 25443]],\n",
       "       shape=(1331, 1536), dtype=uint16)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name, data = extract_data_from_tif(\"./tiffs_for_sem/run2_area_01.tif\")\n",
    "\n",
    "print(name)\n",
    "len(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2be30f4f-db20-4e0c-ba3a-a827a076c0b5",
   "metadata": {},
   "source": [
    "Adesso dobbiamo avere anche un modo per estrarre i metadati. Questa parte è basata sui file tif che ho analizzato dalla clean-room di Trento per cui non è detto che non serviranno degli aggiustamenti in futuro. Prima di tutto creo una funzione di utilità che permette, qualora i metadati da estrarre si trovino per vari motivi in una lista molto lunga nella forma \"NomeQuantità = valore\" e separati dai caratteri \"\\n\"  li va a cercare a uno ad uno tramite regex (a Trento serve per un solo strumento mentre l'altro è più semplice da esportare con gli strumenti dei tif file per cui potrebbe non essere necessario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3b22fd3d-c319-4f02-b0a9-90b656b05c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_quantities(text):\n",
    "    tag_dict={}\n",
    "    pattern=r'([A-Z]\\w+)\\s*=\\s*((?:(?!\\\\n)[^;,])+)'\n",
    "    matches = re.findall(pattern, text)\n",
    "    for name, value in matches:\n",
    "        tag_dict[name] = value\n",
    "\n",
    "    return tag_dict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de60ad65-fb3c-4e41-b670-abca38eeee2a",
   "metadata": {},
   "source": [
    "Grazie a questa possiamo poi definire la funzione di estrazione dei metadati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4d53f800-6549-4974-b1c9-58c6a8c0481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata_from_tif(percorso):\n",
    "    dictionar = {}\n",
    "    with tf.TiffFile(percorso) as tiffile:\n",
    "        dictionar[\"file_name\"] = percorso.split(\"/\")[-1] \n",
    "        for i, page in enumerate(tiffile.pages):\n",
    "            mio_dict = {}\n",
    "            for tag in page.tags:\n",
    "                try:\n",
    "                    if isinstance(tag.value, str) or isinstance(tag.value, float) or isinstance(tag.value, int):\n",
    "                        mio_dict[tag.name] = tag.value\n",
    "                    elif isinstance(tag.value, tuple):\n",
    "                        mio_dict[tag.name] = list(tag.value)\n",
    "                    elif isinstance(tag.value, bytes):\n",
    "                        new = str(tag.value)\n",
    "                        mio_dict |= search_quantities(new)\n",
    "                    elif isinstance(tag.value, dict):\n",
    "                         mio_dict[tag.name] = tag.value\n",
    "                except Exception:\n",
    "                    mio_dict[tag.name] = \"Non leggibile\"\n",
    "            dictionar[f\"page_{i+1}\"] = mio_dict\n",
    "    return dictionar"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00bb8580-3f6d-4496-a4fe-10c6f1a0459f",
   "metadata": {},
   "source": [
    "In pratica questa funzione legge il tif e per ogni pagina di questo file itera una lettura dei tags relativi a quella pagina e i valori corrispondenti.\n",
    "Se tali valori sono semplici numeri o stringhe procede a salvarli senza problemi nel dizionario di output come coppia chiave valore. Se invece sono tuple li trasforma prima in lista (ci piacciono di più le liste) e nel caso peggiore in cui siano bytes opera la trasformazioen di quei bytes in stringa e poi con la funzione di prima inizia a iterare in mezzo alla stringa ottenuta per cercare la quantità come prima. Infine, se i tags vengono letti con strutture annidate e riescono ad avere la forma di dizionari vengono semplicemente appesi al dizionario di uscita.\n",
    "Per cui la struttura finale sarà:\n",
    "\n",
    "dictionar:{\n",
    "    \"file_name\": \"nome_tif_file_analizzato\",\n",
    "    \"pagina_1\": {\n",
    "        I vari tags letti come coppia chiave valore\n",
    "    },\n",
    "    \"pagina_2\": ...\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a8b221b-d886-4c86-a831-e047d2ab4866",
   "metadata": {},
   "source": [
    "Comunque per visualizzare la struttura puoi eseguire la cella successiva (togli il punto e virgola per vedere l'output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf2568-beda-41dc-b123-7d2947ca4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_metadata_from_tif(\"./tiffs_for_sem/U1502_metal_cross_5um_015.tif\");"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f95df70-7b99-484e-9ab3-3228ff96288c",
   "metadata": {},
   "source": [
    "Come hai potuto notare i valori associati nelle chiavi contengono delle stringhe anche se dovessero essere dei numeri in realtà per cui adesso dobbiamo operare due passi fondamentali trasformare i vari valori nel tipo corretto e associargli l'untià di misura corretta. Inoltre, ovviamente ogni strumento avendo dei tag nominati diversamente avrà una struttura a dizionario diversa come output. Noi però vogliamo estrarre i metadati che ci serviranno per scrivere il file nexus alla fine quindi dobbiamo operare insieme alla trasformazione di prima anche un reshaping del dizionario per la forma standardizzata che ci servirà per il nexus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6381d4ef-b6bb-4565-b192-83575f790b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"instrument.name\": {\n",
    "        \"aliases\": [\"name\", \"Device\", \"FEI_HELIOS.System.SystemType\"]\n",
    "    },\n",
    "    \"instrument.fabrication.model\": {\n",
    "        \"aliases\": [\"model\", \"DeviceModel\"]\n",
    "    },\n",
    "    \"instrument.fabrication.manufacturer\": {\n",
    "        \"aliases\": [\"manufacturer\", \"Make\"]\n",
    "    },\n",
    "    \"instrument.detector.type\": {\n",
    "        \"aliases\": [\"Detector\", \"FEI_HELIOS.Detectors.Name\"]\n",
    "    },\n",
    "    \"instrument.program.program.program\":{\n",
    "        \"aliases\": [\"Software\", \"FEI_HELIOS.System.Software\"]\n",
    "    },\n",
    "    \"instrument.program.program.version\":{\n",
    "        \"aliases\":[\"SoftwareVersion\", \"FEI_HELIOS.System.Software\"]\n",
    "    },\n",
    "    \"instrument.ebeam_column.electron_source.emitter_type\":{\n",
    "        \"aliases\":[\"FEI_HELIOS.EBeam.Source\", \"Gun\"]\n",
    "    },\n",
    "    \"events.instrument.optics.magnification\":{\n",
    "        \"aliases\": [\"Magnification\"],\n",
    "        \"get\": lambda input_dict: (\n",
    "            get_nested(input_dict, \"FEI_HELIOS.Image.MagCanvasRealWidth\")\n",
    "            / get_nested(input_dict, \"FEI_HELIOS.Scan.HorFieldsize\")\n",
    "            if get_nested(input_dict, \"FEI_HELIOS.Image.MagCanvasRealWidth\") is not None \n",
    "            and get_nested(input_dict, \"FEI_HELIOS.Scan.HorFieldsize\") is not None \n",
    "            and get_nested(input_dict, \"FEI_HELIOS.Scan.HorFieldsize\") != 0\n",
    "            else None\n",
    "        )\n",
    "    },\n",
    "    \"events.instrument.optics.working_distance\":{\n",
    "        \"aliases\": [\"WD\",\"FEI_HELIOS.EBeam.WD\"],\n",
    "        \"unit\": \"m\"\n",
    "    },\n",
    "    \"events.instrument.optics.probe_current\": {\n",
    "        \"aliases\": [\"PredictedBeamCurrent\", \"FEI_HELIOS.EBeam.BeamCurrent\"],\n",
    "        \"unit\": \"A\"\n",
    "    },\n",
    "    \"events.instrument.optics.tilt_correction\":{\n",
    "        \"aliases\": [\"TiltCorrection\", \"FEI_HELIOS.EBeam.TiltCorrectionIsOn\"],\n",
    "        \"get\": lambda x: (\n",
    "            True if str(x).lower() == \"yes\" or (isinstance(x, (int, float)) and x != 0)\n",
    "            else False\n",
    "        ) \n",
    "    },\n",
    "    \"events.instrument.ebeam_column.operation_mode\":{\n",
    "        \"aliases\": [\"ScanMode\"]\n",
    "    },\n",
    "    \"events.instrument.ebeam_column.electron_source.voltage\":{\n",
    "        \"aliases\": [\"AcceleratorVoltage\", \"FEI_HELIOS.EBeam.HV\"],\n",
    "        \"unit\": \"V\"\n",
    "    },\n",
    "    \"events.instrument.ebeam_column.electron_source.emission_current\":{\n",
    "        \"aliases\": [\"EmissionCurrent\", \"FEI_HELIOS.EBeam.EmissionCurrent\"],\n",
    "        \"unit\": \"A\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6d13eba-d11a-4147-9f2a-d8251b5fbf3b",
   "metadata": {},
   "source": [
    "Abbiamo in questo modo definito un dizionario per \"tradurre\" dal linguaggio delle singole macchine alla struttura simil-nexus. Caratteristica cruciale di questo mapper è che ogni chiave contiene il percorso in uscita (cioè la posizione nel dizionario standard) e come valori dei dizionari contenenti gli aliases di quella quantità, cioè i nomi alternativi presenti negli strumenti analizzati. Se in futuro si volesse analizzare un nuovo strumento per il quale la quantità da associare in \"instrument.name\" si dovrà trovare in \"System.InstrumentName\" basterà aggiungere questa nuova stringa tra gli alias di quella quantità e così via. Il mapper inoltre contiene le istruzioni per le quantità di misura delle grandezze dimensionate. Inoltre in alcuni casi sono state definite dei metodi \"get\" associati a quella classe utili per particolari conversioni per quelle grandezze in maniera tale da rispettare il formato atteso dai nexus e in alcuni casi come er la magnificazione ottenere metadati che non sono direttamente esportabili dai tif ma derivabili dai parametri forniti. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a63bba26-a0bb-4b04-9bea-a0e7ba2cdea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nested(d: dict, path: str, default=None):\n",
    "    keys = path.split(\".\")\n",
    "    for k in keys:\n",
    "        if not isinstance(d, dict) or k not in d:\n",
    "            return default\n",
    "        d = d[k]\n",
    "    return d\n",
    "\n",
    "def set_nested(d: dict, path: str, value):\n",
    "    keys = path.split(\".\")\n",
    "    for k in keys[:-1]:\n",
    "        d = d.setdefault(k, {})\n",
    "    d[keys[-1]] = value"
   ]
  },
  {
   "cell_type": "raw",
   "id": "53424d4c-508d-4b8a-b58b-f5f68934eca2",
   "metadata": {},
   "source": [
    "Nella cella precedente abbiamo definito dei metodi utili nella generazione del dizionario standard e per la lettura di quello originale. In particolare, saremo in grado di ottenere i valori da scrivere generando i percorsi da usare dagli aliases e genereremo anche le posizioni in cui scrivere dalle chiavi del mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9c5b76be-2aa1-491a-9b04-079d963b0348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_parse_number(value: str):\n",
    "    \"\"\"Prova a convertire una stringa in int o float. Se non riesce, restituisce None.\"\"\"\n",
    "    try:\n",
    "        if \".\" in value:\n",
    "            return float(value)\n",
    "        else:\n",
    "            return int(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def generate_numeric_values(numeric_value, unit, output, target_path):\n",
    "    if unit is not None:\n",
    "        set_nested(output, target_path, {\"value\": numeric_value, \"unit\": unit})\n",
    "    else:\n",
    "        set_nested(output, target_path, numeric_value)\n",
    "\n",
    "def transform(input_dict: dict, mapping: dict) -> dict:\n",
    "    output = {}\n",
    "    for target_path, rules in mapping.items():\n",
    "        aliases = rules.get(\"aliases\", [])\n",
    "        unit = rules.get(\"unit\", None)\n",
    "        metodo = rules.get(\"get\", None)\n",
    "        \n",
    "        # Prima prova con gli aliases\n",
    "        value_found = False\n",
    "        for alias in aliases:\n",
    "            value = get_nested(input_dict, alias)\n",
    "            if value is not None:\n",
    "                if isinstance(value, str) and value != \"\":\n",
    "                    numeric_value = try_parse_number(value)\n",
    "                    if numeric_value is not None:\n",
    "                        generate_numeric_values(numeric_value, unit, output, target_path)\n",
    "                        break\n",
    "                    if metodo is not None:\n",
    "                        new=metodo(value)\n",
    "                        set_nested(output, target_path, new)\n",
    "                        break\n",
    "                    else:\n",
    "                        # non parsabile -> salvo come stringa\n",
    "                        set_nested(output, target_path, value)\n",
    "                        break\n",
    "                elif isinstance(value, (int, float)):\n",
    "                    generate_numeric_values(value, unit, output, target_path)\n",
    "                    break\n",
    "                value_found = True\n",
    "                break\n",
    "        \n",
    "        # Se non è stato trovato nessun valore negli aliases, prova con il metodo get\n",
    "        if not value_found and metodo is not None:\n",
    "            computed_value = metodo(input_dict)\n",
    "            if computed_value is not None:\n",
    "                if isinstance(computed_value, (int, float)):\n",
    "                    generate_numeric_values(computed_value, unit, output, target_path)\n",
    "                else:\n",
    "                    set_nested(output, target_path, computed_value)\n",
    "    set_nested(output, \"instrument.m_def\", \"NXem_instrument\")\n",
    "    set_nested(output, \"instrument.fabrication.m_def\", \"NXfabrication\")\n",
    "    set_nested(output, \"instrument.detector.m_def\", \"NXdetector\")\n",
    "    set_nested(output, \"instrument.program.m_def\", \"NXprogram\")\n",
    "    set_nested(output, \"instrument.ebeam_column.m_def\", \"NXebeam_column\")\n",
    "    set_nested(output, \"instrument.ebeam_column.electron_source.m_def\", \"NXsource\")\n",
    "    set_nested(output, \"events.m_def\", \"NXem_event_data\")\n",
    "    set_nested(output, \"events.instrument.optics.m_def\",\"NXem_optical_system\")\n",
    "    set_nested(output, \"events.instrument.m_def\",\"NXem_instrument\")\n",
    "    set_nested(output, \"events.instrument.ebeam_column.m_def\",\"NXebeam_column\")\n",
    "    set_nested(output, \"events.instrument.ebeam_column.electron_source.m_def\",\"NXsource\")    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050ab05-0a32-471b-84fc-f79917497851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instrument': {'name': 'TESCAN NISABA',\n",
       "  'fabrication': {'model': 'L7151',\n",
       "   'manufacturer': 'TESCAN - http://www.tescan.com/',\n",
       "   'm_def': 'NXfabrication'},\n",
       "  'detector': {'type': 'SE #2', 'm_def': 'NXdetector'},\n",
       "  'program': {'program': {'program': 'TESCAN Essence Version 1.3.3.1, build 7979',\n",
       "    'version': 'TESCAN Essence Version 1.3.3.1'},\n",
       "   'm_def': 'NXprogram'},\n",
       "  'ebeam_column': {'electron_source': {'emitter_type': 'Schottky',\n",
       "    'm_def': 'NXsource'},\n",
       "   'm_def': 'NXebeam_column'},\n",
       "  'm_def': 'NXem_instrument'},\n",
       " 'events': {'instrument': {'optics': {'magnification': 7180.1280174,\n",
       "    'working_distance': {'value': 0.00762385, 'unit': 'm'},\n",
       "    'probe_current': {'value': 5.01e-11, 'unit': 'A'},\n",
       "    'tilt_correction': False,\n",
       "    'm_def': 'NXem_optical_system'},\n",
       "   'ebeam_column': {'operation_mode': 'RESOLUTION',\n",
       "    'electron_source': {'voltage': {'value': 5000.0, 'unit': 'V'},\n",
       "     'emission_current': {'value': 0.0001701720035, 'unit': 'A'},\n",
       "     'm_def': 'NXsource'},\n",
       "    'm_def': 'NXebeam_column'},\n",
       "   'm_def': 'NXem_instrument'},\n",
       "  'm_def': 'NXem_event_data'}}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata=extract_metadata_from_tif(\"./tiffs_for_sem/run2_area_01.tif\")\n",
    "\n",
    "for row in metadata:\n",
    "    dict_to_read=transform(metadata[row], mapping)\n",
    "\n",
    "dict_to_read"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3243506-04bf-4ac1-a808-26fc4674c493",
   "metadata": {},
   "source": [
    "Avendo adesso la funzione di trasformazione cercata usiamola per generare, come abbiamo fatto per i dati immagine, una lista di metadati da usare così poi indici corrispoendenti per generare il file nexus. Dobbiamo combinare la funzione di estrazione con quella dei metadati avendo cura di riempire solo i dati di pagina. (In futuro quando avrò un file tiff con più pagine per davvero potrò rivedere la struttura generale, magari in quel caso i dati di strumento sono in un'instestazione globale e al livello di pagine ci sono quelli che il nexus richiede al livello stesso di immagine e non di measurement globale).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "328f56e5-e14e-4ef4-b591-a56aa5abbf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metadata_array(tif_file):\n",
    "    metadata = extract_metadata_from_tif(tif_file)\n",
    "    outputs=[]\n",
    "    for i in range(0,len(metadata.keys())):\n",
    "        output={}\n",
    "        if i==0:\n",
    "            pass\n",
    "        else:\n",
    "            output=transform(metadata[f\"page_{i}\"], mapping)\n",
    "            outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98bcb5e3-d710-472a-8066-6ecedb79e5d9",
   "metadata": {},
   "source": [
    "Infine in quest'ultima cella potremo operare effettivamente le trasformazioni richieste cioè la generazione del tipo corretto e della struttura richiesta. Puoi verificare la forma del dizionario ottenuto dalla prossima cella..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7487947-f35f-4fbf-9542-0ce3d2e904c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadati=generate_metadata_array(\"./tiffs_for_sem/run2_area_01.tif\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a788b87b-07ad-493f-814a-a9d70ab0aa44",
   "metadata": {},
   "source": [
    "Arrivati a questo punto possiamo poi definire la funzione che ci genererà le sezione measurement per il sem quando chiamata e che sfrutterò solo il tif per essere compilata. Certo dovremo anche specificare dove scrivere i vari gruppi e datasets (where). (Per quanto riguarda questa funzione devo pervedere anche di non volere solo generare immagini 2d ma anche stack o altro ma per ora non serve posso al più generare una funzione che prende in argomento il tipo che serve e genera la sezione dentro imaeg di quel tipo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4a9a4c13-2acf-485e-8b05-06c7ed538492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_measurement_section (where, tiff_file):\n",
    "    metadata = generate_metadata_array(tiff_file)\n",
    "    name, dati = extract_data_from_tif(tiff_file)\n",
    "    if len(metadati) != len(dati):\n",
    "        raise(\"Data and metadata do not have the same dimension, both must fill an image with respective metadata\")\n",
    "    else:\n",
    "        for meta in metadati:\n",
    "            write_data(meta, where)\n",
    "        for idx, dat in enumerate(dati):\n",
    "            image=where[\"events\"].create_group(f\"image_{idx}\")\n",
    "            image.attrs[\"NX_class\"]=\"NXimage\"\n",
    "            image_2d = where[\"events\"][f\"image_{idx}\"].create_group(\"image_2d\")\n",
    "            image_2d.attrs[\"NX_class\"] = \"NXdata\"\n",
    "            image_2d.create_dataset(\"title\", data=name)\n",
    "            image_2d.create_dataset(\"real\", data=dat, dtype='uint16')\n",
    "            image_2d.create_dataset(\"axis_i\", data=np.arange(dat.shape[0]))\n",
    "            image_2d.create_dataset(\"axis_j\", data=np.arange(dat.shape[1]))\n",
    "            image_2d.attrs[\"signal\"] = \"real\"\n",
    "            image_2d.attrs[\"axis_i_indices\"] = 0\n",
    "            image_2d.attrs[\"axis_j_indices\"] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3aee9716-eeee-449f-820c-298e2549eaee",
   "metadata": {},
   "source": [
    "E finalemente con questa funzione in mano possiamo a procedere davvero il nexus per il sem ma per farlo dobbiamo importarci dai commons la funzione per aprire i jsons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261d6c52-71eb-4ff2-b4fc-98d1cceeca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"sem_file_auto_pfib.nxs\", \"w\") as f:\n",
    "    entry = f.create_group(\"entry\")\n",
    "    entry.attrs[\"NX_class\"] = \"NXentry\"\n",
    "    entry.attrs[\"default\"] = \"/entry/measurement/events/image_0/image_2d\"\n",
    "    entry.create_dataset(\"definition\", data=\"NXem\")\n",
    "    entry[\"definition\"].attrs[\"version\"] = \"v2024.02\"\n",
    "    entry[\"definition\"].attrs[\"URL\"] = \"https://github.com/FAIRmat-NFDI/nexus_definitions/blob/a85e10cd0289f4e44b0fec011ff54703e6705383/contributed_definitions/NXem.nxdl.xml\"\n",
    "    meas = entry.create_group(\"measurement\")\n",
    "    meas.attrs[\"NX_class\"] = \"NXem_measurement\"\n",
    "    aprire_jsons(\"./Codici e file per sem/jsons_for_sem/\", entry)\n",
    "    write_measurement_section(meas, \"./tiffs_for_sem/U1502_metal_cross_5um_015.tif\")\n",
    "    meas[\"instrument\"].create_dataset(\"location\", data=\"Trento\")\n",
    "    meas[\"instrument\"].create_dataset(\"type\", data=\"sem\")\n",
    "    meas[\"instrument\"][\"ebeam_column\"][\"electron_source\"].create_dataset(\"probe\", data=\"electrons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fe625885-a463-46cd-a381-433ac78a2a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root:NXroot\n",
      "  entry:NXentry\n",
      "    coordinate_system:NXcoordinate_system\n",
      "      handedness = 'right_handed'\n",
      "      origin = 'sample'\n",
      "      type = 'cartesian'\n",
      "    definition = 'NXem'\n",
      "      @URL = 'https://github.com/FAIRmat-NFDI/nexus_definiti...'\n",
      "      @version = 'v2024.02'\n",
      "    end_time = ''\n",
      "    experiment_alias = 'alias'\n",
      "    experiment_description = 'short description'\n",
      "    experiment_identifier = 'experiment_identifier'\n",
      "    measurement:NXem_measurement\n",
      "      events:NXem_event_data\n",
      "        image:NXimage\n",
      "          image_2d:NXdata\n",
      "            @axis_i_indices = 0\n",
      "            @axis_j_indices = 1\n",
      "            @signal = 'real'\n",
      "            axis_i = int64(1331)\n",
      "            axis_j = int64(1536)\n",
      "            real = uint16(1331x1536)\n",
      "            title = 'run2_area_01'\n",
      "          instrument:NXem_instrument\n",
      "            ebeam_column:NXebeam_column\n",
      "              electron_source:NXsource\n",
      "                emission_current = 0.0001701720035\n",
      "                  @units = 'A'\n",
      "                voltage = 5000.0\n",
      "                  @units = 'V'\n",
      "              operation_mode = 'RESOLUTION'\n",
      "          optics:NXem_optical_system\n",
      "            magnification = 7180.1280174\n",
      "            probe_current = 5.01e-11\n",
      "              @units = 'A'\n",
      "            tilt_correction = False\n",
      "            working_distance = 0.00762385\n",
      "              @units = 'm'\n",
      "      instrument:NXem_instrument\n",
      "        detector:NXdetector\n",
      "          type = 'SE #2'\n",
      "        ebeam_column:NXebeam_column\n",
      "          emitter_type = 'Schottky'\n",
      "        fabrication:NXfabrication\n",
      "          manufacturer = 'TESCAN - http://www.tescan.com/'\n",
      "          model = 'L7151'\n",
      "        name = 'TESCAN NISABA'\n",
      "        program:NXprogram\n",
      "          program = 'TESCAN Essence Version 1.3.3.1, build 7979'\n",
      "            @version = 'TESCAN Essence Version 1.3.3.1'\n",
      "    sample:NXsample\n",
      "      atom_types = 'Si, O'\n",
      "      identifier_sample = 'sample_ID'\n",
      "      is_simulation = True\n",
      "      name = 'Sample SEM'\n",
      "      physical_form = 'bulk'\n",
      "      preparation_date = ''\n",
      "    start_time = ''\n",
      "    user:NXuser\n",
      "      ORCID = '0009-0004-3810-1808'\n",
      "      address = 'Povo(TN)'\n",
      "      affiliation = 'FBK'\n",
      "      email = 'mbontorno@fbk.eu'\n",
      "      facility_user_id = 'MB'\n",
      "      name = 'Matteo Bontorno'\n",
      "      role = 'Collaborator'\n"
     ]
    }
   ],
   "source": [
    "from nexusformat.nexus import *\n",
    "\n",
    "test = nxload(\"sem_file_auto.nxs\")\n",
    "print(test.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0732bd08-cf49-4f84-801d-9649f66b2159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
